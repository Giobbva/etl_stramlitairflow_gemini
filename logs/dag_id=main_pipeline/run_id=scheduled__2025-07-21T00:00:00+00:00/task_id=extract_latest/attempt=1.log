[2025-07-22T16:23:47.416+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T16:23:47.420+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T16:23:47.421+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T16:23:47.432+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T16:23:47.437+0000] {standard_task_runner.py:60} INFO - Started process 192 to run task
[2025-07-22T16:23:47.441+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmp7n84l3yb']
[2025-07-22T16:23:47.442+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask extract_latest
[2025-07-22T16:23:47.474+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host dc5230c5617d
[2025-07-22T16:23:47.529+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T16:23:48.276+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T16:23:48.278+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T16:23:48.285+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T162347, end_date=20250722T162348
[2025-07-22T16:23:48.336+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T16:23:48.357+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T16:52:09.052+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T16:52:09.059+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T16:52:09.060+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T16:52:09.071+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T16:52:09.077+0000] {standard_task_runner.py:60} INFO - Started process 184 to run task
[2025-07-22T16:52:09.081+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpb7f33bhi']
[2025-07-22T16:52:09.083+0000] {standard_task_runner.py:88} INFO - Job 4: Subtask extract_latest
[2025-07-22T16:52:09.120+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 37f452463ac0
[2025-07-22T16:52:09.177+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T16:52:09.892+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T16:52:09.894+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T16:52:09.901+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T165209, end_date=20250722T165209
[2025-07-22T16:52:09.936+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T16:52:09.953+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T16:57:05.049+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T16:57:05.057+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T16:57:05.057+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T16:57:05.069+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T16:57:05.076+0000] {standard_task_runner.py:60} INFO - Started process 190 to run task
[2025-07-22T16:57:05.081+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpu46r44ir']
[2025-07-22T16:57:05.083+0000] {standard_task_runner.py:88} INFO - Job 5: Subtask extract_latest
[2025-07-22T16:57:05.128+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host bf2339095885
[2025-07-22T16:57:05.192+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T16:57:06.132+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T16:57:06.133+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T16:57:06.141+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T165705, end_date=20250722T165706
[2025-07-22T16:57:06.178+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T16:57:06.192+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T17:01:38.489+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:01:38.496+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:01:38.497+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T17:01:38.509+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T17:01:38.517+0000] {standard_task_runner.py:60} INFO - Started process 193 to run task
[2025-07-22T17:01:38.520+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpzlfl2ffj']
[2025-07-22T17:01:38.522+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask extract_latest
[2025-07-22T17:01:38.561+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 2646d8340d4b
[2025-07-22T17:01:38.621+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T17:01:39.154+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T17:01:39.155+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T17:01:39.162+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T170138, end_date=20250722T170139
[2025-07-22T17:01:39.215+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T17:01:39.241+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T17:06:01.771+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:06:01.777+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:06:01.777+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T17:06:01.787+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T17:06:01.792+0000] {standard_task_runner.py:60} INFO - Started process 187 to run task
[2025-07-22T17:06:01.796+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmp1syttil2']
[2025-07-22T17:06:01.798+0000] {standard_task_runner.py:88} INFO - Job 3: Subtask extract_latest
[2025-07-22T17:06:01.828+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 4cc1f9709e63
[2025-07-22T17:06:01.879+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T17:06:02.514+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T17:06:02.516+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T17:06:02.525+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T170601, end_date=20250722T170602
[2025-07-22T17:06:02.570+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T17:06:02.589+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T17:16:52.345+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:16:52.352+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:16:52.352+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T17:16:52.363+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T17:16:52.369+0000] {standard_task_runner.py:60} INFO - Started process 195 to run task
[2025-07-22T17:16:52.372+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpm3o6t53o']
[2025-07-22T17:16:52.374+0000] {standard_task_runner.py:88} INFO - Job 3: Subtask extract_latest
[2025-07-22T17:16:52.409+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host c31d04d11063
[2025-07-22T17:16:52.466+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T17:16:53.193+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T17:16:53.194+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T17:16:53.201+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T171652, end_date=20250722T171653
[2025-07-22T17:16:53.228+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T17:16:53.243+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T17:31:00.829+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:31:00.835+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:31:00.835+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T17:31:00.846+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T17:31:00.851+0000] {standard_task_runner.py:60} INFO - Started process 202 to run task
[2025-07-22T17:31:00.854+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpq9l4xzar']
[2025-07-22T17:31:00.856+0000] {standard_task_runner.py:88} INFO - Job 3: Subtask extract_latest
[2025-07-22T17:31:00.894+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 289823fc3070
[2025-07-22T17:31:00.953+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T17:31:01.545+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T17:31:01.546+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T17:31:01.551+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T173100, end_date=20250722T173101
[2025-07-22T17:31:01.590+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T17:31:01.604+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T17:40:43.771+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:40:43.778+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:40:43.778+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T17:40:43.788+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T17:40:43.793+0000] {standard_task_runner.py:60} INFO - Started process 191 to run task
[2025-07-22T17:40:43.796+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpa1gf8cuv']
[2025-07-22T17:40:43.798+0000] {standard_task_runner.py:88} INFO - Job 6: Subtask extract_latest
[2025-07-22T17:40:43.835+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 610cf35e4eb3
[2025-07-22T17:40:43.894+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T17:40:45.531+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T17:40:45.532+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T17:40:45.539+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T174043, end_date=20250722T174045
[2025-07-22T17:40:45.577+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T17:40:45.594+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-22T17:47:39.029+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:47:39.035+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T17:47:39.035+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T17:47:39.043+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T17:47:39.048+0000] {standard_task_runner.py:60} INFO - Started process 192 to run task
[2025-07-22T17:47:39.050+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmp6lyc38p2']
[2025-07-22T17:47:39.051+0000] {standard_task_runner.py:88} INFO - Job 3: Subtask extract_latest
[2025-07-22T17:47:39.081+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 17392357f595
[2025-07-22T17:47:39.132+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T17:47:39.553+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T17:47:39.555+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T17:47:39.560+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T174739, end_date=20250722T174739
[2025-07-22T17:47:39.584+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T17:47:39.601+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-22T18:22:03.712+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T18:22:03.719+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [queued]>
[2025-07-22T18:22:03.720+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-07-22T18:22:03.731+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): extract_latest> on 2025-07-21 00:00:00+00:00
[2025-07-22T18:22:03.738+0000] {standard_task_runner.py:60} INFO - Started process 199 to run task
[2025-07-22T18:22:03.740+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'main_pipeline', 'extract_latest', 'scheduled__2025-07-21T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/main_pipeline.py', '--cfg-path', '/tmp/tmpanfy7yui']
[2025-07-22T18:22:03.742+0000] {standard_task_runner.py:88} INFO - Job 6: Subtask extract_latest
[2025-07-22T18:22:03.780+0000] {task_command.py:423} INFO - Running <TaskInstance: main_pipeline.extract_latest scheduled__2025-07-21T00:00:00+00:00 [running]> on host 44387cd0f964
[2025-07-22T18:22:03.837+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='main_pipeline' AIRFLOW_CTX_TASK_ID='extract_latest' AIRFLOW_CTX_EXECUTION_DATE='2025-07-21T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-21T00:00:00+00:00'
[2025-07-22T18:22:04.813+0000] {logging_mixin.py:188} INFO - ✅ Datos en streaming extraídos (Frankfurter)
[2025-07-22T18:22:04.814+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-07-22T18:22:04.820+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=main_pipeline, task_id=extract_latest, execution_date=20250721T000000, start_date=20250722T182203, end_date=20250722T182204
[2025-07-22T18:22:04.838+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-07-22T18:22:04.851+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
